\chapter[Introduction]{Introduction}

Compiler optimizations play a key role in improving program execution speed and overall system performance. Most existing optimization techniques are implemented using imperative programming approaches. This project explored an alternative by applying logic programming, specifically Prolog, to express compiler optimizations. The work was carried out within the GraalVM compiler framework. The project first assessed the feasibility of using a declarative logic-based approach for compiler optimizations within GraalVM. It then examined how this approach compares to traditional methods in terms of performance and expressiveness. Finally, it evaluated whether optimization rules could be effectively described and applied using Prolog.

Logic programming languages with declarative specifications allow programs to be analyzed efficiently through queries. By focusing on what needs to be done rather than how to do it, declarative approaches offer greater clarity and intuitiveness. This inherent simplicity and readability facilitates experimentation with new optimization rules, as well as the maintenance of existing ones. Additionally, declarative code can be easier to verify correctness because it is more straightforward and easier to follow. Previous research has extensively utilized Datalog, a prominent logic programming language, for different levels of program analysis \cite{Bravenboer2009,Tonder2021,Lam2005,Benton2007}. However, there is a notable lack of prior work applying logic programming languages specifically to code optimization and transformation. Spinellis’s work in 1999 explored expressing optimizations through declarative specifications rather than traditional imperative code \cite{Spinellis1999}. However, that work was limited to a rudimentary prototype optimizer with a ``single optimization specification'' and ``limited flow-of-control optimizations'' \cite{Spinellis1999}.

This project developed a Prolog-based optimization framework that integrates with the GraalVM compiler. The approach involved four main steps, developed in parallel to ensure compatibility. 
First, GraalVM IR nodes were translated directly into Prolog terms suitable for Prolog queries.
Second, optimization rules were written in Prolog using a declarative style to describe transformations such as canonicalization, conditional elimination, and loop invariant reassociation. Third, Prolog queries were executed from within GraalVM using Projog, a Java-based Prolog interpreter, to identify potential optimization. Finally, a recursive descent parser was implemented to interpret the results returned by the Prolog engine. As each optimization was applied, the IR was updated and reconstructed, leading to an improved program representation. Together, these steps enabled a functional integration of logic-based optimization into the GraalVM compilation process. To ensure correctness, new tests were developed and existing GraalVM test suites were leveraged to verify the behavior of Prolog rules and validate the integration.

The framework’s performance was evaluated based on optimization throughput, measured as the number of optimization operations performed per second. An operation is defined as the process of building the IR graph for a method and applying the optimization phases. Overall, the study demonstrates the feasibility of integrating Prolog-based optimizations into GraalVM and highlights both the strengths and limitations of this approach. Results showed that Prolog’s declarative syntax is well-suited for expressing stateless optimizations like canonicalization. However, more complex, state-dependent transformations such as conditional elimination faced performance challenges, mainly due to limitations in the Prolog’s engine (Projog) slow startup time.

\chapter[Introduction]{Introduction}

Compiler optimizations play a key role in improving program execution speed and overall system performance. Most existing optimization techniques are implemented using imperative programming approaches. This project explores an alternative by applying logic programming, specifically Prolog, to express compiler optimizations. The work is carried out within the GraalVM compiler framework. The project assesses the feasibility of using a declarative logic-based approach for compiler optimizations within GraalVM. A comparison is made between this approach and traditional methods in terms of performance and expressiveness. Finally, we evaluate whether optimization rules could be effectively described and applied using Prolog.

Logic programming languages with declarative specifications allow source programs to be analyzed efficiently through queries. By focusing on what needs to be done rather than how to do it, declarative approaches offer greater clarity and intuitiveness. This inherent simplicity and readability facilitates experimentation with new optimization rules, as well as the maintenance of existing ones. Additionally, declarative code can be easier to verify correctness because it is more straightforward and easier to follow. Previous research has extensively utilized Datalog, a prominent logic programming language, for different levels of program analysis \cite{Bravenboer2009,Tonder2021,Lam2005,Benton2007}. However, there is a notable lack of prior work applying logic programming languages specifically to code optimization and transformation. Spinellis’ work in 1999 explored expressing optimizations through declarative specifications rather than traditional imperative code \cite{Spinellis1999}. However, that work was limited to a rudimentary prototype optimizer with a ``single optimization specification'' and ``limited flow-of-control optimizations'' \cite{Spinellis1999}.

This project develops a Prolog-based optimization framework that integrates with the GraalVM compiler. The approach involved four main steps, developed in parallel to ensure compatibility. 
First, GraalVM IR nodes are translated into Prolog terms suitable for Prolog queries.
Second, optimization rules are written in Prolog using a declarative style to describe transformations. 
Third, Prolog queries are executed from within GraalVM using Projog, a Java-based Prolog interpreter, to identify potential optimizations. Finally, a recursive descent parser interprets the results returned by Prolog. Each optimization transforms and reconstructs the IR, leading to an optimized program representation.
Together, these steps enables the integration of logic-based optimizations into the GraalVM compilation process. 
To ensure correctness, the existing GraalVM test suites and new test cases verify the behavior of Prolog rules and validate the integration.

This project implements and evaluates three optimizations: canonicalization, conditional elimination, and loop-invariant reassociation. These are selected to cover a range of optimization types, from simple canonicalization rules to more complex transformations involving control flow and data dependencies.

The framework’s performance is evaluated based on optimization throughput, measured as the number of optimization operations performed per second.
An optimization operation is defined as the process of building the IR graph for a method and applying the optimization phases.
Overall, the study demonstrates the feasibility of integrating Prolog-based optimizations into GraalVM and highlights both the strengths and limitations of this approach.
The results show that Prolog’s declarative syntax is well-suited for expressing stateless optimizations like canonicalization. However, more complex, state-dependent transformations such as conditional elimination faced performance challenges, mainly due to limitations in the Prolog’s engine (Projog) slow startup time.
